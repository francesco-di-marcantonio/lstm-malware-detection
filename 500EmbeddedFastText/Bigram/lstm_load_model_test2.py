# coding=utf-8

#python lstm_load_model.py compresso compresso report/ vecFile/trigram_skipgram_modo_loro_epoch1.vec  1  1
"""
@author: Sto cazzo
"""
from __future__ import absolute_import, division, print_function, unicode_literals

import tensorflow as tf
import numpy as np
import csv
import time
import pandas as pd
from keras.preprocessing import sequence
from keras.models import model_from_json
from sklearn.metrics import precision_score, recall_score, classification_report,accuracy_score, f1_score
from sklearn.externals import joblib
from sklearn.metrics import confusion_matrix
from datetime import datetime
import sys

#francesco
from keras.preprocessing.text import Tokenizer
from tensorflow.python.client import device_lib


path_model='model/'









def fasttextPreTrained(vecfile):
    ######################################
    # EMBEDDING LAYER
    #####################################
    embeddings_index = {}
    f = open(vecfile, "r")
    embedding_word = {}
    for line in f:
        values = line.split()
        word = values[0]
        coefs = np.asarray(values[1:], dtype='float32')
        embeddings_index[word] = coefs
    f.close()
    print('Found %s word vectors.' % len(embeddings_index))
    return embeddings_index



def evaluate(y_test, y_pred, f_report, start, end,valid_class,flag_bin,datasetname, report_folder):    
    # Take the dga's names
    #labels_names = list(dga_dict.keys())
    target_names=valid_class.keys()

    y_test = np.array(y_test)
    y_test = y_test.ravel()

    class_report = classification_report(y_test, y_pred,digits=4, target_names = target_names)
    
    
    #Macro and micro f1score,precision and recall all dataset
    score_macro = f1_score(y_test, y_pred,average="macro")
    precision_macro = precision_score(y_test, y_pred,average="macro")
    recall_macro = recall_score(y_test, y_pred,average="macro")
    score_micro = f1_score(y_test, y_pred,average="micro")
    precision_micro = precision_score(y_test, y_pred,average="micro")
    recall_micro = recall_score(y_test, y_pred,average="micro")
    matrix=[]
    matrix.append([score_macro, score_micro])
    matrix.append([precision_macro,precision_micro])
    matrix.append([recall_macro, recall_micro])
    matrix=np.array(matrix)
    colonne=["macro","micro"]
    indici=["f1_score", "precision", "recall"]
    df = pd.DataFrame(matrix,index=indici,columns=colonne)
    print ("F1_score Precision Recall dataset \n")
    print (df)
    
    f_report.write("\n\nTesting (minutes)" + str((end-start)/float(60)) + '\n')
    
    accuracy = accuracy_score(y_test,y_pred)
    f_report.write("\nClass report: \n" + class_report)
    f_report.write("\nF1_score Precision Recall dataset \n" + str(df))
    f_report.write("\n\nOverall accuracy = " + str(accuracy) + '\n\n')
    f_report.write("\nAccuracy for each class:\n")


    # Accuracy for each class
    c_matrix = confusion_matrix(y_test,y_pred)
    cm_acc = c_matrix.astype('float') / c_matrix.sum(axis=1)[:, np.newaxis]
    accuracy_each_class = cm_acc.diagonal()
    
    # The following cicle is to format and print the accuracy
    count_name = 0
    print ("\nAccuracy for each class:\n")
    for acc_cls in accuracy_each_class:
        print('{:>14} {:1}'.format(str(target_names[count_name]), str(round(acc_cls,3)))+'\n')
        f_report.write('{:>14} {:1}'.format(str(target_names[count_name]), str(round(acc_cls,3)))+'\n')
        count_name +=1
    
    f_report.write("\n \n")
	
    print(class_report)
    

    TP = np.diag(c_matrix)
    TP = np.sum(TP)
    TotalElement = np.asmatrix(c_matrix)
    TotalElement = np.sum(TotalElement)
    f_report.write("\nTrue positive: "+str(TP)+"\n")
    print ("\nTrue positive: "+str(TP)+"\n")
    f_report.write("\n \n")
    
    f_total_report= open(report_folder + "/total_report.csv", 'a')
    if flag_bin==True:
        report_row = "binary" + ";" + datasetname+".csv" + ";"+ '%.5f'%(precision_micro)  + ";" + '%.5f'%(precision_macro)  + ";" + '%.5f'%(recall_micro) + ";" + '%.5f'%(recall_macro) + ";" + '%.5f'%(score_micro) + ";" + '%.5f'%(score_macro)+ ";"  + '%.5f'%(accuracy)+ ";"  + str(TP) + ";" + str(TotalElement) + "\n"
    else:
        report_row = "multi" + ";" + datasetname+ ".csv" + ";"+ '%.5f'%(precision_micro)  + ";" + '%.5f'%(precision_macro)  + ";" + '%.5f'%(recall_micro) + ";" + '%.5f'%(recall_macro) + ";" + '%.5f'%(score_micro) + ";" + '%.5f'%(score_macro)+ ";"  + '%.5f'%(accuracy)+";"  + str(TP) + ";" + str(TotalElement) + "\n"
    f_total_report.write(report_row)
    print("\nRisultati scritti correttamente nel report.\n")
    f_total_report.close()

def get_data(datasetname): 
	"""Read data from file (Traning, testing and validation) to process"""
	data= []
	with open(datasetname+".csv", "r") as f:
		reader = csv.reader(f)
		for row in reader:
			data.append(row)
	return data

def run(date, datasetname, train_model, path_report,vecFile,epoch,folds):

    #print ("Num GPUs Available: ", len(tf.config.experimental.list_physical_devices('GPU')))

    trained_model = "model/bigram_binary_" + datasetname.replace("TEST","TRAIN") + "_epochs_"+epoch+"_folds_"+folds
    #trained_model = "binary_" + "0-day_conficker_train_h_t_domins" + "_epochs_20_folds_1"
    multi_trained_model = "model/bigram_multi_" + datasetname.replace("TEST","TRAIN") + "_epochs_"+epoch+"_folds_"+folds
    """Run train/test on logistic regression model"""
    #Begin preprocessing stage
    #Read data to process
    indata = get_data(datasetname) # + "_white_A_full"
    
    # Extract data and labels
    binary_labels = [x[0] for x in indata] #legit o dns
    X_test = [x[4] for x in indata] #DNS   #X2 è la stringa di caratteri, X4 è la stringra di bigrammi e trigrammi
    #print X
    labels = [x[1] for x in indata] #famiglia dga
    #####  TOKEN DI BIGRAMMI O TRIGRAMMI #####
    # Generate dictionary for word (bigram or trigram)
    #oov_token=None
    tokenizer = Tokenizer(1384,filters='!"#$%&()*,./:;<=>?@[\\]^`{|}~\t\n',oov_token="<UKN>")  ##AGGiunti i filtri per accettare i simboli nei token
    tokenizer.fit_on_texts(X_test)
    word_index = tokenizer.word_index
    sequences = tokenizer.texts_to_sequences(X_test) #le parole sono state associate ad un numero che è l'indice del dizionario
    maxlen = np.max([len(x) for x in X_test])
    ##############
    ##################
    #print sequences
    #X_test = sequences.pad_sequences(X_test, maxlen=maxlen)
    #max_features = 1384
    #maxlen=1385
    #
    #print (maxlen)
    X_test = sequence.pad_sequences(sequences,maxlen=maxlen)
    #########--EMBEDDING -- ########################
    #embeddings_index = fasttextPreTrained(vecFile)
    #EMBEDDING_DIM = 128
    #1375 è la dimensione del dataset del dizionari bigrammi TEST
    #embedding_matrix = np.zeros((len(word_index) , EMBEDDING_DIM))
    #for word, i in word_index.items():
    #    embedding_vector = embeddings_index.get(word)
    #    if embedding_vector is not None:
    #        # words not found in embedding index will be all-zeros.
    #        embedding_matrix[i] = embedding_vector
    ###### CARATTERI ##########
    '''
    # Generate a dictionary of valid characters
    valid_chars = {x:idx+1 for idx, x in enumerate(set(''.join(X)))}
    #print binary_labels
    maxlen = np.max([len(x) for x in X])

    # Convert characters to int and pad
    X_test = [[valid_chars[y] for y in x] for x in X]
    X_test = sequence.pad_sequences(X_test, maxlen=maxlen)
    '''
    # Convert labels to 0-1 for binary class
    y_binary = np.array([0 if x == 'legit' else 1 for x in binary_labels])
    # Convert labels to 0-37 for multi class
    valid_class = {i:indx for indx, i in enumerate(set(labels))}
    y_dga = [valid_class[x] for x in labels]
    y_dga = np.array(y_dga)
    white=valid_class['alexa']
    #End preprocessing stage
    
    start = time.time()
    print ("Carico il modello binario")
    #model_binary = joblib.load("model/" + trained_model)
    json_file = open( trained_model + ".json", 'r')
    loaded_model_json = json_file.read()
    json_file.close()
    model_binary = model_from_json(loaded_model_json)
    model_binary.load_weights(trained_model + ".h5")   
    
    #Salvataggio variabili per report binary
    y_pred = model_binary.predict(X_test, verbose=1)
    y_bin_result = [0 if(x<=0.5) else 1 for x in y_pred]
    
    print ('Carico il modello multiclasse')
    #model_dga = joblib.load("model/" + multi_trained_model)
    json_file = open( multi_trained_model + ".json", 'r')
    loaded_model_json = json_file.read()
    json_file.close()
    model_dga = model_from_json(loaded_model_json)
    model_dga.load_weights(multi_trained_model + ".h5")      
    

    y_pred = model_binary.predict_proba(X_test, verbose=1)
    y_result = [white if(x<=0.5) else 0 for x in y_pred]
    
    
    end=time.time()
    
    
    X_dga_test =[]
    y_dga_test_labels =[]
    for i in range(len(y_result)):
        if y_result[i] == 0:
            X_dga_test.append(X_test[i]) 
            y_dga_test_labels.append(y_dga[i]) #Valori veri dei dga
    X_dga_test = np.array(X_dga_test)
    y_dga_test_labels = np.array(y_dga_test_labels)
    y_pred_dga = model_dga.predict_proba(X_dga_test)
    y_result_dga = [np.argmax(x) for x in y_pred_dga]
    #End of multiclass classification stage
    

    j = 0
    for i in range(len(y_result)):
        if y_result[i] != white:
            y_result[i] = y_result_dga[j]
            j = j+1

    #Calculate the final result multi class
    print ("\n\nMulticlass report: \n")
    f_report_multi=open(path_report+"report_multiclass_"+datasetname+"_"+str(date.year)+"_"+str(date.strftime("%m"))+"_"+str(date.strftime("%d"))+"-"+str(date.strftime("%H"))+"-"+str(date.strftime("%M"))+".txt", 'a')
    evaluate(y_dga,y_result,f_report_multi,start,end,valid_class,False,datasetname,path_report)
    f_report_multi.close()
    #end multiclass report
    

    #Calculate final result binary
    print ("\n\nBinary report: \n")
    f_report_binary=open(path_report+"report_binary_supervised_"+str(date.year)+"_"+str(date.strftime("%m"))+"_"+str(date.strftime("%d"))+"-"+str(date.strftime("%H"))+"-"+str(date.strftime("%M"))+".txt", 'a')
    class_binary={'white':0 , 'black':1}
    evaluate(y_binary,y_bin_result,f_report_binary,start,end,class_binary,True, datasetname,path_report)
    f_report_binary.close()
    #End binary report

date=datetime.now()
if __name__ == "__main__":
    run(date, sys.argv[1], sys.argv[2], sys.argv[3],sys.argv[4],sys.argv[5],sys.argv[6])
